# Level 1
1. Знает, что такое Garbage Collector, зачем нужен
2. Знает, что такое счетчик ссылок
3. Понимает, как работает __del__ (a.__del__(); del a)
4. Знает в теории, что такое memory profiler и для каких целей используются инструменты профилирования памяти


### Вопрос: что такое Garbage Collector, зачем нужен?

Ответ: 

***Garbage Collector (GC)*** — *это механизм автоматического управления памятью в Python, 
который отвечает за удаление объектов, на которые больше нет ссылок, 
освобождая занимаемую ими память. Это необходимо, чтобы избежать утечек памяти, 
когда объекты больше не используются*

### Вопрос: что такое счетчик ссылок?

Ответ:

***Счетчик ссылок*** — *это механизм, который отслеживает количество ссылок на каждый объект в памяти. 
Когда счетчик ссылок объекта достигает нуля, это означает, что объект больше не используется, 
и его можно безопасно удалить.*

### Вопрос: как работает __del__ ```(a.del(); del a)```?

Ответ:

*В Python сборщик мусора автоматически управляет памятью. 
Сборщик мусора уничтожает объекты, на которые нет ссылок.
Если в объекте реализован метод ```__del__```, Python вызывает этот метод непосредственно перед тем, 
как сборщик мусора уничтожит объект. Однако именно сборщик мусора определяет, 
когда уничтожить объект. Поэтому именно он решает, когда будет вызван метод ```___del__```.
Метод del иногда называют ***финализатором класса***. Обратите внимание, 
что del не является деструктором, потому что объект уничтожает сборщик мусора, а не сам метод ```__del__```. 
Подводные камни метода Python ```__del__```:
Python вызывает метод ```__del__``` только тогда, когда все ссылки на объект исчезают. 
И в большинстве случаев вы не можете контролировать этот процесс.
Поэтому не следует использовать метод ```__del__``` для очистки ресурсов. Рекомендуется использовать менеджер контекста. 
Если в методе del есть ссылки на другие объекты, то сборщик мусора также уничтожит эти объекты, 
когда будет вызван del. 
Если метод del ссылается на глобальные объекты, это может вызвать неожиданные поведения. 
Если в методе ```__del__``` возникает исключение, Python не вызывает исключение, а тихо его игнорирует. 
Кроме того, Python отправляет сообщение об исключении в stderr. 
Поэтому основная программа сможет узнать о возникших исключениях во время финализации. 
На практике метод ```__del__``` используется довольно редко.*
```python
class Person:
    def __init__(self, name, age):
        self.name = name
        self.age = age

    def __del__(self):
        print('__del__ был вызван')

person_1 = Person('John Doe', 23)
person_1 = None

person_2 = Person('John Doe', 23)
del person_2
```
Результат:
``` python
__del__ был вызван

__del__ был вызван
```
***Однако оператор del не вызывает метод ```__del__```, если объект имеет ссылку.***

***Резюме:***
Python вызывает метод del непосредственно перед тем, как сборщик мусора уничтожит объект.
Сборщик мусора уничтожает объект, когда на него нет ссылок.
Исключения, возникающие внутри метода del, не вызываются, а игнорируются.
Избегайте использования del для очистки ресурсов, вместо этого используйте менеджер


### Вопрос: что такое memory profiler и для каких целей используются инструменты профилирования памяти?

Ответ:

***Memory profiler*** - это инструмент для мониторинга использования памяти программой. 
Он помогает выявить, какие части кода используют слишком много памяти.
Профилировка памяти позволяет анализировать распределение памяти на уровне объектов, 
что помогает оптимизировать код.

```python
from memory_profiler import profile

@profile
def my_function():
    a = [1] * (10 ** 6)  # Пример использования памяти
    b = [2] * (2 * 10 ** 7)  # Пример использования памяти
    return a

if __name__ == "__main__":
    my_function()
```
***Преимущества***: Позволяет точно отслеживать использование памяти для каждой функции. 
Легко интегрируется в код с помощью декораторов.

***Ограничения***: Работает только для Python-кода и не предоставляет подробной информации на уровне системной памяти.

***Дополнительно:***
В Python существует несколько популярных инструментов для профилирования памяти, 
каждый из которых имеет свои особенности и предназначение. Вот основные из них:

tracemalloc:

Это встроенный модуль Python (начиная с версии 3.4), 
который позволяет отслеживать использование памяти во время выполнения программы, 
включая информацию о распределении памяти по строкам кода.
```python
import tracemalloc

tracemalloc.start()

# Пример кода
a = [1] * (10 ** 6)
b = [2] * (2 * 10 ** 7)

print(f"Текущий уровень памяти: {tracemalloc.get_traced_memory()}")
tracemalloc.stop()

```
***Преимущества:*** 

Позволяет отслеживать все выделения памяти, 
включая их источник (например, строка кода). Встроен в Python.

***Ограничения:*** 

Может замедлять выполнение программы при интенсивном использовании.

guppy3 (Heapy):

Это библиотека для профилирования памяти в Python, которая предоставляет детальный анализ использования памяти, 
включая возможность просматривать объекты в куче.
```python
from guppy import hpy

h = hpy()
print(h.heap())  # Печатает информацию о текущем состоянии памяти

```
***Преимущества:*** 

Он предоставляет подробные отчеты о состоянии памяти и структуре объектов в куче.

***Ограничения:*** 

Может быть сложным для использования, если нужно только базовое профилирование.

psutil:

Это библиотека для работы с процессами и системной информацией. 
Она позволяет отслеживать использование памяти на уровне всей программы (не только Python-объектов), 
а также анализировать использование памяти операционной системой.
```python
import psutil
process = psutil.Process()
print(f"Использование памяти: {process.memory_info().rss}")

```
***Преимущества:*** 

Позволяет отслеживать использование памяти не только в Python-программе, но и на уровне операционной системы.

***Ограничения:*** 

Не предоставляет подробностей о распределении памяти внутри Python-кода.

objgraph:

Библиотека для визуализации графа объектов и их связей в памяти. 
Помогает выявить утечки памяти, показывая, какие объекты ссылаются друг на друга.
```python
import objgraph

# Показывает граф объектов
objgraph.show_most_common_types()

```
***Преимущества:*** 

Отлично подходит для обнаружения утечек памяти и анализа ссылок между объектами.

***Ограничения:*** 

Не предоставляет информацию о фактическом использовании памяти в байтах.

# Level 2
1. Понимает что хранится в heap/stack memory в python
2. Знает, как использовать slots, а также их предназначение и ограничения
3. Знает оба механизма сборки мусора (Refcounter/Generations)


### Вопрос: что хранится в heap/stack memory в Python

Ответ:

Heap (куча):
Здесь хранятся все объекты: списки, словари, пользовательские классы, строки, числа и т.д.
Это динамическая область памяти, которая может расти по требованию программы.
Управляется сборщиком мусора (GC).
```python
def my_func():
    a = [1, 2, 3]  # создаётся список

my_func()
```
Когда my_func() вызывается, создаётся список [1, 2, 3], и переменная a указывает на него.
После завершения my_func(), переменная a удаляется (она была в стеке).
На список [1, 2, 3] больше нет ссылок → GC удалит его из памяти.

Все объекты в Python размещаются в куче, а переменные на стеке — это ссылки на эти объекты.

Stack (стек) используется для хранения имён и ссылок на объекты и 
служебные данные(указатель на предыдущий фрейм и адрес возврата) для выполнения кода. 
Управляется автоматически: 
когда функция вызывается — создаётся стековый фрейм(кадр), 
когда завершается — фрейм(кадр) удаляется.

***Важное:*** Даже если переменная создаётся внутри функции, 
например x = 5, сама переменная (ссылка) находится в стеке, а значение 5 — в куче.
В Python все значения — это объекты, и они всегда хранятся в куче, а переменные просто ссылаются на них.

Что происходит, когда ты пишешь x = 5 внутри функции?

Python видит, что ты создаёшь переменную x и присваиваешь ей значение 5.
Python создаёт объект числа 5 в куче (heap) — это специальная область памяти, 
где хранятся все объекты (числа, строки, списки, классы и т.д.).
В стек (stack) — то есть память, 
где хранится информация о выполнении функций, — помещается переменная x, которая содержит ссылку на объект 5 в куче.

📌 Что значит "ссылка"?

Это как ярлык или указатель: x не содержит само число, а указывает на объект 5, который лежит в куче.
Ты можешь создать другую переменную y = x, и она тоже будет указывать на тот же объект 5 в куче.

🧠 Почему так сделано?

Потому что в Python всё — это объект, и чтобы было единообразие, все объекты (даже числа) лежат в куче, 
а переменные — это просто ссылки на них.
Это позволяет, например:
передавать переменные между функциями,
экономить память (один объект — много ссылок),
управлять временем жизни объектов через сборщик мусора.
```python
def my_func():
    x = 5
```
5 — создаётся как объект в куче (если его там ещё нет).

x — создаётся в стеке этой функции и ссылается на объект 5.

Если ты потом сделаешь:
```python
y = x
```
y — это новая переменная (тоже в стеке), которая тоже ссылается на тот же самый объект 5 в куче.

### Вопрос: как использовать __slots__, а также их предназначение и ограничения?

Ответ:

```__slots__``` — это ***механизм Python***, 
позволяющий ограничить список допустимых атрибутов объекта и сэкономить память.
Зачем нужны:

Обычные Python-объекты используют словарь __dict__ для хранения атрибутов — он гибкий, но занимает много памяти.
Если задать __slots__, Python создаёт фиксированный набор атрибутов и не создаёт ```__dict__```, что:
Уменьшает потребление памяти.
Повышает скорость доступа к атрибутам (в некоторых случаях).
```python
class Point:
    __slots__ = ('x', 'y')  # разрешены только эти два атрибута

    def __init__(self, x, y):
        self.x = x
        self.y = y
```
Ограничения:

- Нельзя добавлять произвольные новые атрибуты (ошибка AttributeError).

- Не поддерживается множественное наследование с разными ```__slots__``` без дополнительной настройки.
```python
class A:
    __slots__ = ('a',)

class B:
    __slots__ = ('b',)

class C(A, B):  # ❌ Ошибка TypeError
    pass

```
❗ TypeError: multiple bases have instance lay-out conflict

🤔 Почему?

Каждый класс с ```__slots__``` создаёт специальную структуру хранения данных без обычного словаря атрибутов. 
При множественном наследовании с разными ```__slots__``` возникает конфликт: Python не знает, 
как разместить слоты разных родителей в одной структуре.

- Не работает с ```__dict__``` и ```__weakref__``` по умолчанию (если не указать явно в ```__slots__```).

Когда ты используешь ```__slots__```, Python отключает автоматическое создание:
```__dict__``` — словаря атрибутов (в нём обычно хранятся динамические поля).
```__weakref__``` — поддержки слабых ссылок на объект.

Это и даёт экономию памяти, но ограничивает возможности.

❗ Что если тебе всё-таки нужны:

Возможность добавлять новые поля динамически,
или чтобы объект можно было использовать в weakref (например, в кэше).

```python
class MyClass:
    __slots__ = ('x', '__dict__', '__weakref__')

    def __init__(self):
        self.x = 42

```
```__dict__``` — разрешает добавление новых атрибутов как обычно (obj.new_attr = 123)
```__weakref__``` — делает объект доступным для модуля weakref

📌 Если не указать ```__dict__```:
```python
class MyClass:
    __slots__ = ('x',)

obj = MyClass()
obj.y = 10  # ❌ AttributeError: 'MyClass' object has no attribute 'y'

```
📌 Если не указать ```__weakref__```:
```python
import weakref

class MyClass:
    __slots__ = ('x',)

obj = MyClass()
ref = weakref.ref(obj)  # ❌ TypeError: cannot create weak reference to 'MyClass' object
```


### Вопрос: расскажи про оба механизма сборки мусора (Refcounter / Generations)

Ответ:

В Python используется два механизма сборки мусора:

***Reference Counting (Счётчик ссылок)*** — 🔧 основной механизм

📌 Как работает:

У каждого объекта в Python есть счётчик ссылок (reference count).
Этот счётчик показывает, сколько переменных/объектов ссылаются на данный объект.
Как только счётчик становится нулевым — объект удаляется немедленно.

✅ Преимущества:

Очень быстро и предсказуемо.
Не требует прохода по памяти — освобождение происходит моментально.

❗ Минус:

Не справляется с циклическими ссылками, например:
```python
class Node:
    def __init__(self):
        self.ref = None

a = Node()
b = Node()

a.ref = b
b.ref = a
```
Теперь a и b ссылаются друг на друга, 
даже если в программе они больше нигде не используются → счётчик ссылок не станет нулевым → утечка памяти.




***Generational Garbage Collector (Сборка мусора по поколениям)***

📌 Зачем нужен:
Решает проблему циклических ссылок, с которыми не справляется счётчик ссылок.

📦 Принцип "поколений":
Python делит объекты на три поколения:

Gen 0 — все новые объекты

Gen 1 — выжившие из Gen 0

Gen 2 — выжившие из Gen 1, самые "старые"

🕵️ Как работает:

Когда создаётся новый объект — он попадает в Gen 0.
Когда срабатывает сборка мусора:

Сначала проверяется Gen 0 — это быстро.
Если после сборки мусора объекты ещё используются — они переходят в Gen 1.
Если выжили и там — попадают в Gen 2.
Gen 2 проверяется реже всего (оптимизация производительности).

⚙️ Алгоритм:

GC "ходит по ссылкам" между объектами (граф объектов), 
чтобы найти недостижимые объекты (на которые никто не ссылается).
Если находится изолированный цикл объектов — они удаляются.
Используется трассировка ссылок, но только для объектов в куче (heap), стек не участвует.

🧠 Почему стек не участвует?

В стеке хранятся переменные и ссылки, но не сами объекты.
Объекты — всегда в куче, и GC работает именно с кучей.
Когда функция завершает работу, стек автоматически очищается, 
и ссылки исчезают — если на объекты больше никто не ссылается → они сразу удаляются (reference count = 0).
```python
import gc

print(gc.get_count())  # ➜ покажет, сколько объектов в каждом поколении (0, 1, 2)
gc.collect()            # ➜ вручную запускает сборку мусора

```

# Level 3
1. Понимает, как организован доступ к виртуальной памяти (Arena/Pool/Block)
2. Может описать алгоритмы работы механизмов сборки мусора
3. Понимает как GIL связан с GC
4. Имеет опыт работы с memory profiler
5. Имеет опыт оптимизации потребления памяти
6. Знает как устроен PyObject (концептуально, что в нем хранится)

### Вопрос: как организован доступ к виртуальной памяти (Arena/Pool/Block)

Ответ:

Python использует свою собственную систему для работы с памятью — она называется pymalloc
📌 pymalloc = способ быстро выделять и освобождать память под маленькие объекты.

Эта система работает только с маленькими объектами, которые занимают меньше 512 байт.
Если объект большой — используется стандартный способ из языка С, называется malloc.
📌 malloc = обычный способ взять память у операционной системы.

✅ 1. Arena (Арена) — 🧱 большой склад памяти
Размер: 256 КБ — это довольно большой кусок памяти

Арена — это то, что Python просит у операционной системы
📌 ОС = операционная система (например, Windows, Linux)

Одна арена делится на много маленьких участков — они называются пулы

🔎 Зачем арены?

Чтобы не просить у операционной системы память каждый раз. 
Это долго и тяжело. Лучше один раз взять большой кусок и уже внутри него раздавать маленькие.

✅ 2. Pool (Пул) — 📦 ящик с одинаковыми ячейками
Размер: 4 КБ — это стандартный размер страницы памяти в ОС

Один пул может выделять только блоки одного размера
📌 Например, только по 16 байт, или только по 64 байта. Не смешиваются!

Один арена содержит много пулов

📌 Почему одинаковый размер?

Это упрощает учёт — Python легко понимает, какие куски заняты, какие свободны.

✅ 3. Block (Блок) — 🔲 маленькая ячейка внутри пула
Это и есть та самая память, которую получает объект Python (например, число или строка)

Размер блока зависит от того, какой пул его выдал
📌 Пример:

Пул с блоками по 16 байт → каждый объект получит 16 байт

Пул с блоками по 64 байта → каждый объект получит 64 байта

🧠 Пример из жизни:

У вас есть объект, который весит 40 байт
Python выберет пул на 48 байт
Вы получите 1 блок — но реально займёте 48 байт, хоть использовали только 40


Arena = 256 KB содержит до 64 пулов (если каждый пул по 4 KB)
Один пул может:
  - Содержать 256 блоков по 16 байт
  - Или 64 блока по 64 байта
Каждый блок = память для одного PyObject

🧠 Почему это удобно?
- Python не делает медленные запросы к ОС каждый раз
- Объекты группируются по размеру — проще отслеживать
- Если блок освобождён, Python может использовать его снова
- Когда вся арена пустая — можно вернуть память ОС

🔄 Как освобождается память

Когда все блоки в пуле свободны, пул считается неиспользуемым.
Когда все пулы в арене свободны, вся арена возвращается операционной системе

### Вопрос: опиши алгоритмы работы механизмов сборки мусора

Ответ:

📌 GC = Garbage Collector = сборщик мусора
Это система, которая автоматически удаляет неиспользуемые объекты, чтобы освободить память

🧠 Простыми словами:
Когда вы создаёте переменные в Python — они занимают память.
Когда переменная уже не нужна, Python должен понять это и освободить память сам.

🔍 В Python есть два основных механизма GC:
- Подсчёт ссылок (Reference Counting)
```python
a = [1, 2, 3]
b = a
```
Объект [1, 2, 3] теперь имеет 2 ссылки (одна в a, другая в b)
Когда a и b удаляются — счётчик становится 0
Python сразу удаляет объект

Это работает мгновенно, прямо во время выполнения

📌 Плюсы:

Просто и быстро
📌 Минусы:

Не решает проблему циклов


- Сборка циклов (Cycle Collector)

Иногда объекты ссылаются друг на друга, и счётчик ссылок никогда не становится нулём.

Пример:
```python
class Node:
    def __init__(self):
        self.ref = self

x = Node()
```
У x есть ссылка на самого себя → цикл.
Даже если удалить x, внутри объекта всё ещё есть ссылка → не сработает счётчик

💡 Поэтому Python запускает специальный цикл-детектор

🔄 Как работает сборка циклов:

- Python время от времени запускает проверку на циклы
- Он смотрит на объекты, которые могут быть частью цикла
- Если объекты не видны из основного кода, но ссылаются друг на друга → Python удаляет их

📦 Python делит объекты на поколения (Generations)
Чтобы не проверять всё подряд, Python делит объекты по "возрасту":

- 0 поколение — новые объекты
- 1 поколение — те, кто "выжил" после 1-й проверки
- 2 поколение — выжившие после 2-й

📌 Объекты, которые "живут долго", проверяются реже, чтобы не тратить ресурсы.

### Вопрос: как GIL связан с GC?

Ответ:

***GIL (Global Interpreter Lock)*** — это глобальная блокировка интерпретатора
📌 GIL - механизм, который не даёт нескольким потокам исполнять Python-код одновременно, 
даже на многоядерных процессорах.

📌 Что важно:

Сборка мусора (GC) зависит от GIL
→ потому что GC работает с памятью, которую могут использовать разные потоки

🧠 Простыми словами:

- В Python память управляется автоматически (через GC)
- Если один поток удаляет объект, а другой поток в это же время ссылается на него — будет ошибка или утечка памяти
- Чтобы избежать этого — GIL блокирует другие потоки во время операций с памятью

🔐 Что конкретно делает GIL:
- Когда Python запускает сборку мусора — он держит GIL, чтобы никакой другой поток не мешал
- Подсчёт ссылок (Reference Counting) — всегда под защитой GIL
потому что увеличение/уменьшение счётчиков ссылок происходит очень часто
- GC-проверка циклов — тоже работает только при наличии GIL

🔄 Зачем это нужно?
💣 Без GIL, если два потока одновременно изменят счётчик ссылок одного объекта, может произойти:

- double free (удаление уже удалённого объекта)
- dangling pointer (ссылка на несуществующий объект)
- утечка памяти (объект остался, но не нужен)

GIL гарантирует безопасность памяти при сборке мусора.

### Вопрос: если GIL защищает память в многопоточности, что насчёт мультипроцессности?

🔑 Ответ:

📌 В мультипроцессности (через multiprocessing в Python), каждый процесс имеет свою отдельную память.
→ Они не делят объекты между собой напрямую.

⚙️ Каждый процесс:

- Имеет свою собственную копию интерпретатора Python
- И, соответственно, свой GIL
- И свой механизм GC

📦 Что это значит?
- GIL не нужен для защиты между процессами, потому что у них нет общей памяти
- Каждый процесс отдельно управляет своей памятью
- Если один процесс запускает GC — это никак не влияет на другие процессы

⚠️ ***Но при передаче объектов между процессами происходит копирование, а не совместный доступ***

❓ "Почему в CPython GC работает безопасно в многопроцессорном окружении?"

🔑 Потому что каждый процесс имеет свой собственный интерпретатор, свою память, свой GIL и свой GC.
→ Между процессами нет конкуренции за доступ к памяти, и, следовательно, не нужна защита GIL между ними.

### Вопрос: расскажи об опыте использования инструментов профилирования памяти.

Ответ:

***Memory profiler*** — это инструмент, который показывает:
- Сколько памяти используется
- Какими строками/функциями кода
- Когда и почему происходит рост использования памяти

✅ 1. memory_profiler — 📏 измеряет потребление памяти по строкам.

```
pip install memory-profiler
```
```python
from memory_profiler import profile

@profile
def my_func():
    a = [x for x in range(1000)]
    return a

my_func()

```
```
Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   141     23.3 MiB     23.3 MiB           1   @profile
   142                                         def my_func():
   143     23.4 MiB      0.1 MiB        1001       a = [x for x in range(1000)]
   144     23.4 MiB      0.0 MiB           1       print(a)
```

🔍 Что значит каждая колонка:
- Mem usage – сколько всего памяти использовалось после выполнения этой строки.
- Increment – насколько изменилась (увеличилась) память по сравнению с предыдущей строкой.
- Occurrences – сколько раз эта строка была выполнена (вызвана).
- Line Contents – сама строка кода.

✅ 2. tracemalloc — 🔍 встроенный в Python (c 3.4+), отслеживает источники аллокации памяти
```python
import tracemalloc

tracemalloc.start()

# ваш код
a = [x for x in range(1000000)]

snapshot = tracemalloc.take_snapshot()
top_stats = snapshot.statistics('lineno')

for stat in top_stats[:5]:
    print(stat)

```
🧠 Он покажет: в каком месте кода создаются самые "тяжёлые" объекты

✅ 3. objgraph — визуализирует ссылки между объектами
- Показывает где и какие объекты "застряли" в памяти.
- ожет отрисовать граф ссылок между объектами.
- Помогает понять, почему объект не удаляется — на него может остаться неожиданная ссылка.
```
pip install objgraph
```
```python
import objgraph

class MyClass:
    def __init__(self):
        self.ref = self

# Создаём "утечку"
leak = MyClass()

# Показываем, какие объекты остались
objgraph.show_backrefs([leak], filename='leak.png')
```
📘 Что происходит:
- MyClass ссылается сам на себя (через self.ref = self) — это цикл.
- Мы создаём объект leak, и даже если бы удалили переменную leak, объект остался бы в памяти, если не запущен GC или если на него осталась ссылка где-то ещё.

📊 Что делает objgraph.show_backrefs:

Строит граф, который показывает:
- какие объекты ссылаются на leak,
- через какие поля,
- и почему Python не удалил объект.

📁 В результате будет создан файл leak.png с графом.

- 🛠 Полезен, когда нужно найти почему объект не удаляется (утечка).

💡 Дополнительно:

Возможно потребуется установка Graphviz
```
sudo pacman -S graphviz
```
```
sudo apt install graphviz
```
```
brew install graphviz
```

```objgraph.show_growth()``` — показывает, каких объектов стало больше всего с последнего запуска.

```objgraph.get_referrers(obj)``` — вручную получить объекты, которые ссылаются на obj.




# TODO доделать абзац 


### Вопрос: как устроен PyObject (концептуально, что в нем хранится)

Ответ:

Всё в Python является объектами. Например, откройте консоль своей IDE(у меня PyCharm) и введите:
```
>>> isinstance(1, object)
True
>>> isinstance(list(), object)
True
>>> isinstance(True, object)
True
>>> def foo():
...    pass
...
>>> isinstance(foo, object)
True
```
Отсюда следует вывод, что всё в python - объекты!

Каждый объект (PyObject) содержит минимум 2 вида данных:
- Счётчик ссылок на экземпляр ([Refcounter](#вопрос-расскажи-про-оба-механизма-сборки-мусора-refcounter--generations))
- Тип объекта (Тип используется на уровне CPython для обеспечения типобезопасности в ходе исполнения (runtime))
```
Поле	                    Тип	                  Назначение
ob_refcnt                   Py_ssize_t            Счётчик ссылок на экземпляр

ob_type                     _typeobject*          Тип объекта
```

Так же нужно понимать, что объекты в python бывают изменяемые(mutable) и не изменяемые(immutable)

```id()``` - показывает адрес памяти объекта

```
id(x)
134235416319056
x += 1
id(x)
134235416319088
```
Мы видим, что после изменения значения, мы получаем новый объект, с новым адресом памяти. 

Со строками та же ситуация:
```
s = "I Wanna "
id(s)
134235383862960
s += "Rock"
s
'I Wanna Rock'
id(s)
134235404419248
```
После операции +=, s получает другой адрес памяти.

+= - это метод ```__iadd__()```. Метод который должен изменять объект, а не создавать новый, 
но так как мы работаем с неизменяемыми объектами, он работает как ```__add__()```
Если мы будем работать с изменяемыми объектами он сохранит адрес памяти:
```
lst = [1, 2, 3]
id(lst)
134235380881984
lst.append(4)  # добавили 4 в конец списка
lst.extend([5, 6])  # добавили 5, 6 в конец списка
lst[0] = 7  # заменили [0] на значение 7
lst
[7, 2, 3, 4, 5, 6]
id(lst)
134235380881984
lst += [1]  # добавили 1 в конец списка
id(lst)
134235380881984  # <-- id объекта остался прежнем
lst
[7, 2, 3, 4, 5, 6, 1]
```

PyObject — это базовая структура всех объектов в CPython. 
Она содержит счётчик ссылок на объект и указатель на сам объект соответствующего типа.
PyObject может представлять любые объекты Python, включая списки, словари, сокеты, 
файлы, целые числа, строки, функции и классы.
Поскольку C не является объектно- ориентированным языком в отличии от Python, 
объекты в C не наследуются один из другого. 
PyObject выступает изначальным сегментом данных для каждого объекта Python, 
а PyObject * представляет ссылку на него.

Интернированные (interned) объекты - подмножество объектов, которые python создаёт в памяти и 
хранит их в глобальном пространстве имён для повседневного использования.

- Целые числа от -5 до 256
- Строки, содержащие только ASCII-буквы, цифры или знаки подчёркивания.

Строки размером меньше 20 символов и содержащие ASCII-буквы, цифры или знаки подчёркивания будут интернированы, 
поскольку предполагается, что они будут применяться в качестве идентификаторов:
```
s_1 = "new_name"
id(s_1)
126823916577712
s_2 = "new_name"
id(s_2)
126823916577712
```
Ссылки на статьи: 

https://habr.com/ru/companies/vk/articles/454324/, 
http://onreader.mdl.ru/CPythonInternals/content/Ch11.html,
https://pythonextensionpatterns.readthedocs.io/en/latest/refcount.html#pyobjects-and-reference-counting


### Вопрос: оптимизация в python

я перечислю лишь некоторые приёмы для оптимизации кода:
- ```__slots__``` - это атрибут, параметр или Dunder-метод, 
позволяющий оптимально потреблять память, выделенную под объект. 
Он определяет имена атрибутов экземпляра заранее и не позволяет добавлять атрибуты экземпляра, 
не прописанные в слотах. Также этот Dunder-метод ограничивает создание новых атрибутов в экземплярах класса.
Использование слотов экономит память, 
так как экземпляры не создают словарь dict для хранения атрибутов (по умолчанию класс создаёт dict).
- Singleton - шаблон проектирования, гарантирующий, что у класса будет только один экземпляр.
- JIT (Just-In-Time) Компиляция 
- lru_cache - Декоратор lru_cache используется для кэширования результатов функций, 
что помогает ускорить выполнение при многократных вызовах одной и той же функции с одинаковыми аргументами.
- Использовать библиотеки с оптимизированными С-реализациями (numpy, scipy)
- Использовать генераторы
- Использовать алгоритмы с низким временем сложности
- Использование join() вместо конкатенации строк
- Использование map(), или генераторы списков(LC) вместо циклов
- Избегание глобальных переменных, Чем меньше область видимости переменных, тем быстрее Python может их обработать. 
Локальные переменные обрабатываются быстрее, чем глобальные.
- Использование set для проверки вхождения вместо list
Ссылки: https://akeidev.ru/blog/pages/blog/dev_python/optimization_py.html#_10
